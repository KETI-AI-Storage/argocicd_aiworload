###############################################################################
# YOLO Inference Workload
# - Type: IMAGE (Computer Vision)
# - Framework: PyTorch + Ultralytics
# - Stage: Inference
# - Deployment (지속 실행) - Object Detection
###############################################################################
apiVersion: apps/v1
kind: Deployment
metadata:
  name: yolo-inference
  namespace: ai-workload-test
  labels:
    app: yolo-inference
    workload-type: image
    framework: pytorch
    stage: inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app: yolo-inference
  template:
    metadata:
      labels:
        app: yolo-inference
        workload-type: image
        framework: pytorch
    spec:
      schedulerName: ai-storage-scheduler

      tolerations:
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule

      shareProcessNamespace: true

      containers:
      #=========================================================================
      # YOLO Inference Container
      #=========================================================================
      - name: inference
        image: python:3.11-slim
        command:
        - python3
        - -c
        - |
          import time
          import sys
          import os
          import random

          # 프로세스 이름 - yolo, vision, image, opencv, detection 키워드
          sys.argv[0] = 'yolov8_opencv_image_detector.py'

          print("=" * 60)
          print("KETI AI Storage - YOLOv8 Inference Service")
          print("=" * 60)
          print(f"Framework: PyTorch + Ultralytics YOLOv8")
          print(f"Model: YOLOv8-large")
          print(f"Task: Real-time Object Detection")
          print("=" * 60)

          os.makedirs('/models/yolo', exist_ok=True)
          os.makedirs('/data/images', exist_ok=True)
          os.makedirs('/data/results', exist_ok=True)

          # 모델 로딩 시뮬레이션
          print("Loading YOLOv8 model weights...")
          with open('/models/yolo/yolov8l.pt', 'wb') as f:
              f.write(os.urandom(80 * 1024 * 1024))  # 80MB model
          print("Model loaded!")

          # 입력 이미지 시뮬레이션 생성
          print("Preparing test images...")
          for i in range(10):
              # 1920x1080 RGB 이미지
              img_size = 1920 * 1080 * 3
              with open(f'/data/images/frame_{i}.jpg', 'wb') as f:
                  f.write(os.urandom(min(img_size, 500 * 1024)))  # ~500KB JPEG
          print("Test images ready!")

          frame_count = 0
          total_objects = 0

          print("\nStarting inference loop...")
          while True:
              frame_count += 1

              # 이미지 로딩 (Read I/O - 이미지 워크로드의 핵심)
              img_file = f'/data/images/frame_{frame_count % 10}.jpg'
              with open(img_file, 'rb') as f:
                  img_data = f.read()

              # 추론 시뮬레이션
              inference_start = time.time()

              # 객체 탐지 결과 시뮬레이션
              num_objects = random.randint(3, 15)
              total_objects += num_objects

              detections = []
              classes = ['person', 'car', 'truck', 'bicycle', 'dog', 'cat', 'traffic_light']
              for _ in range(num_objects):
                  det = {
                      'class': random.choice(classes),
                      'confidence': random.uniform(0.6, 0.99),
                      'bbox': [random.randint(0, 1000), random.randint(0, 500),
                               random.randint(100, 400), random.randint(100, 300)]
                  }
                  detections.append(det)

              # 결과 저장 (Write I/O)
              result_file = f'/data/results/detection_{frame_count % 100}.json'
              with open(result_file, 'w') as f:
                  import json
                  json.dump({
                      'frame': frame_count,
                      'objects': num_objects,
                      'detections': detections[:3]  # 일부만 저장
                  }, f)

              inference_time = time.time() - inference_start + random.uniform(0.02, 0.05)

              if frame_count % 10 == 0:
                  fps = 1.0 / (inference_time + 1.5)  # sleep 포함
                  print(f"[{time.strftime('%H:%M:%S')}] Frame #{frame_count}: {num_objects} objects, {inference_time*1000:.1f}ms, ~{fps:.1f} FPS")

              time.sleep(1.5)  # 1.5초 간격

        ports:
        - containerPort: 8080
          name: http
        resources:
          requests:
            cpu: "300m"
            memory: "512Mi"
          limits:
            cpu: "1500m"
            memory: "2Gi"
        volumeMounts:
        - name: model-volume
          mountPath: /models
        - name: data-volume
          mountPath: /data

      #=========================================================================
      # Insight-Trace Sidecar
      #=========================================================================
      - name: insight-trace
        image: ketidevit2/insight-trace:latest
        imagePullPolicy: Always
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: APOLLO_ENDPOINT
          value: "apollo-policy-server.keti.svc.cluster.local:50051"
        - name: METRICS_INTERVAL
          value: "5s"
        - name: ANALYSIS_INTERVAL
          value: "10s"
        - name: REPORT_INTERVAL
          value: "30s"
        ports:
        - containerPort: 9090
          name: http
        - containerPort: 9091
          name: grpc
        resources:
          requests:
            cpu: "50m"
            memory: "64Mi"
          limits:
            cpu: "200m"
            memory: "256Mi"
        volumeMounts:
        - name: model-volume
          mountPath: /models
          readOnly: true
        - name: data-volume
          mountPath: /data
          readOnly: true

      volumes:
      - name: model-volume
        emptyDir:
          sizeLimit: 500Mi
      - name: data-volume
        emptyDir:
          sizeLimit: 500Mi
